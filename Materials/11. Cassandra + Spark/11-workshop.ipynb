{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cassandra + Spark. Workshop.\n",
    "\n",
    "Для работы в этом ноутбуке запустите jupyter, выполнив команду:  \n",
    "```bash\n",
    "sh /home/mf2019q2/mf_surname/pyspark-jupyter.sh $PORT1 $PORT2\n",
    "```\n",
    "\n",
    "## На этом семинаре:\n",
    "+ знакомство с ```cqlsh```\n",
    "+ создание таблиц\n",
    "+ чтение и запись данных\n",
    "+ работа с композитными ключами\n",
    "+ использовать Spark Cassandra Connector\n",
    "\n",
    "```cqlsh``` - основная утилита, которая позволяет подключаться к Cassandra в интерактивном режиме. Для подключения к кластеру просто выполните команду ```cqlsh virtual-node01``` в командной строке. Обычно при подключении к кластеру также требуется указать логин и пароль. Но на нашем тестовом стенде это не нужно :)\n",
    "\n",
    "Также, используя флаг -e, можно выполнять запросы, не запуская интерактивного шелла, например:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE KEYSPACE system WITH replication = {'class': 'LocalStrategy'}  AND durable_writes = true;\n",
      "\n",
      "CREATE TABLE system.available_ranges (\n",
      "    keyspace_name text PRIMARY KEY,\n",
      "    ranges set<blob>\n",
      ") WITH bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'available keyspace/ranges during bootstrap/replace that are ready to be served'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.batches (\n",
      "    id timeuuid PRIMARY KEY,\n",
      "    mutations list<blob>,\n",
      "    version int\n",
      ") WITH bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'batches awaiting replay'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '2'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.prepared_statements (\n",
      "    prepared_id blob PRIMARY KEY,\n",
      "    logged_keyspace text,\n",
      "    query_string text\n",
      ") WITH bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'prepared statements'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.\"IndexInfo\" (\n",
      "    table_name text,\n",
      "    index_name text,\n",
      "    PRIMARY KEY (table_name, index_name)\n",
      ") WITH COMPACT STORAGE\n",
      "    AND CLUSTERING ORDER BY (index_name ASC)\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'built column indexes'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.views_builds_in_progress (\n",
      "    keyspace_name text,\n",
      "    view_name text,\n",
      "    generation_number int,\n",
      "    last_token text,\n",
      "    PRIMARY KEY (keyspace_name, view_name)\n",
      ") WITH CLUSTERING ORDER BY (view_name ASC)\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'views builds current progress'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.peers (\n",
      "    peer inet PRIMARY KEY,\n",
      "    data_center text,\n",
      "    host_id uuid,\n",
      "    preferred_ip inet,\n",
      "    rack text,\n",
      "    release_version text,\n",
      "    rpc_address inet,\n",
      "    schema_version uuid,\n",
      "    tokens set<text>\n",
      ") WITH bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'information about known peers in the cluster'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.compaction_history (\n",
      "    id uuid PRIMARY KEY,\n",
      "    bytes_in bigint,\n",
      "    bytes_out bigint,\n",
      "    columnfamily_name text,\n",
      "    compacted_at timestamp,\n",
      "    keyspace_name text,\n",
      "    rows_merged map<int, bigint>\n",
      ") WITH bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'week-long compaction history'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 604800\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.sstable_activity (\n",
      "    keyspace_name text,\n",
      "    columnfamily_name text,\n",
      "    generation int,\n",
      "    rate_120m double,\n",
      "    rate_15m double,\n",
      "    PRIMARY KEY ((keyspace_name, columnfamily_name, generation))\n",
      ") WITH bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'historic sstable read rates'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.peer_events (\n",
      "    peer inet PRIMARY KEY,\n",
      "    hints_dropped map<uuid, int>\n",
      ") WITH bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'events related to peers'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.paxos (\n",
      "    row_key blob,\n",
      "    cf_id uuid,\n",
      "    in_progress_ballot timeuuid,\n",
      "    most_recent_commit blob,\n",
      "    most_recent_commit_at timeuuid,\n",
      "    most_recent_commit_version int,\n",
      "    proposal blob,\n",
      "    proposal_ballot timeuuid,\n",
      "    proposal_version int,\n",
      "    PRIMARY KEY (row_key, cf_id)\n",
      ") WITH CLUSTERING ORDER BY (cf_id ASC)\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'in-progress paxos proposals'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.LeveledCompactionStrategy'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.batchlog (\n",
      "    id uuid PRIMARY KEY,\n",
      "    data blob,\n",
      "    version int,\n",
      "    written_at timestamp\n",
      ") WITH bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = '*DEPRECATED* batchlog entries'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '2'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.size_estimates (\n",
      "    keyspace_name text,\n",
      "    table_name text,\n",
      "    range_start text,\n",
      "    range_end text,\n",
      "    mean_partition_size bigint,\n",
      "    partitions_count bigint,\n",
      "    PRIMARY KEY (keyspace_name, table_name, range_start, range_end)\n",
      ") WITH CLUSTERING ORDER BY (table_name ASC, range_start ASC, range_end ASC)\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'per-table primary range size estimates'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.built_views (\n",
      "    keyspace_name text,\n",
      "    view_name text,\n",
      "    status_replicated boolean,\n",
      "    PRIMARY KEY (keyspace_name, view_name)\n",
      ") WITH CLUSTERING ORDER BY (view_name ASC)\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'built views'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.range_xfers (\n",
      "    token_bytes blob PRIMARY KEY,\n",
      "    requested_at timestamp\n",
      ") WITH bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'ranges requested for transfer'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.local (\n",
      "    key text PRIMARY KEY,\n",
      "    bootstrapped text,\n",
      "    broadcast_address inet,\n",
      "    cluster_name text,\n",
      "    cql_version text,\n",
      "    data_center text,\n",
      "    gossip_generation int,\n",
      "    host_id uuid,\n",
      "    listen_address inet,\n",
      "    native_protocol_version text,\n",
      "    partitioner text,\n",
      "    rack text,\n",
      "    release_version text,\n",
      "    rpc_address inet,\n",
      "    schema_version uuid,\n",
      "    thrift_version text,\n",
      "    tokens set<text>,\n",
      "    truncated_at map<uuid, blob>\n",
      ") WITH bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'information about the local node'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.transferred_ranges (\n",
      "    operation text,\n",
      "    keyspace_name text,\n",
      "    peer inet,\n",
      "    ranges set<blob>,\n",
      "    PRIMARY KEY ((operation, keyspace_name), peer)\n",
      ") WITH CLUSTERING ORDER BY (peer ASC)\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = 'record of transferred ranges for streaming operation'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n",
      "CREATE TABLE system.hints (\n",
      "    target_id uuid,\n",
      "    hint_id timeuuid,\n",
      "    message_version int,\n",
      "    mutation blob,\n",
      "    PRIMARY KEY (target_id, hint_id, message_version)\n",
      ") WITH COMPACT STORAGE\n",
      "    AND CLUSTERING ORDER BY (hint_id ASC, message_version ASC)\n",
      "    AND bloom_filter_fp_chance = 0.01\n",
      "    AND caching = {'keys': 'ALL', 'rows_per_partition': 'NONE'}\n",
      "    AND comment = '*DEPRECATED* hints awaiting delivery'\n",
      "    AND compaction = {'class': 'org.apache.cassandra.db.compaction.SizeTieredCompactionStrategy', 'enabled': 'false', 'max_threshold': '32', 'min_threshold': '4'}\n",
      "    AND compression = {'chunk_length_in_kb': '64', 'class': 'org.apache.cassandra.io.compress.LZ4Compressor'}\n",
      "    AND crc_check_chance = 1.0\n",
      "    AND dclocal_read_repair_chance = 0.0\n",
      "    AND default_time_to_live = 0\n",
      "    AND gc_grace_seconds = 0\n",
      "    AND max_index_interval = 2048\n",
      "    AND memtable_flush_period_in_ms = 3600000\n",
      "    AND min_index_interval = 128\n",
      "    AND read_repair_chance = 0.0\n",
      "    AND speculative_retry = '99PERCENTILE';\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cqlsh virtual-node01 -e 'DESCRIBE KEYSPACE system'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keyspace в Cassandra - это аналог database в классических БД. Любая таблица в Cassandra создается в одном из keyspace. В Cassandra есть несколько системных keyspace, например system, system_schema и system_auth. \n",
    "\n",
    "Фактор репликации (количество реплик) устанавливается на уровне keyspace. Создать keyspace можно с помощью следующей команды:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cqlsh virtual-node01 -e \\\n",
    "\"CREATE KEYSPACE IF NOT EXISTS mf WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 3}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В таблице system_schema.table содержится список всех таблиц в каждом keyspace. Выведем список всех таблиц в keyspace ```mf```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " keyspace_name | table_name\n",
      "---------------+------------\n",
      "            mf |   students\n",
      "\n",
      "(1 rows)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cqlsh virtual-node01 -e \\\n",
    "\"select keyspace_name, table_name from system_schema.tables WHERE keyspace_name = 'mf'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Задача 1\n",
    "Получите описание таблицы ```mf.students```:\n",
    "+ Какие поля в ней присутствуют?\n",
    "+ Какие типы у каждого поля?\n",
    "+ Какое поле является ключевым?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте новую запись в этой таблице с информацией о себе:\n",
    "+ org - организация, в которой вы работаете ('megafon')\n",
    "+ age - ваш возраст\n",
    "+ first_name - имя\n",
    "+ last_name - фамилия\n",
    "+ student_id - уникальный идентификатор студента\n",
    "+ job_role - ваша должность.\n",
    "\n",
    "В качестве примера я заполнил данные о себе.\n",
    "\n",
    "Вам не обязательно придумывать UUID. В Cassandra есть функция ```uuid()```, которая генеририует случайный UUID4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2\n",
    "Скооперируйтесь с коллегами и убедитесь, что все создали свои записи в ```mf.students```\n",
    "Выведите содержмое таблицы на экран. \n",
    "\n",
    "+ все ли работаете как надо? Если нет, то почему? Исправьте ошибку.\n",
    "+ продумайте схему данных, оптимизированную для выполнения следующего запроса: **какой максимальный возраст у сотрудников ```megafon``` с фамилией ```Ivanov```?**\n",
    "+ напишите запрос, который будет отвечать на этот вопрос"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3\n",
    "+ добавьте в таблицу новую колонку favourite_city text\n",
    "+ заполните ее городом в США с большой буквы (например, Boston), который бы вы хотели посетить в ближайшем будущем\n",
    "\n",
    "Добавить колонку сможет самый проворный :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 4\n",
    "Прочитайте знакомый вам датасет ```hdfs:///data/spark_excercise/nbagames.json``` с помощью Spark\n",
    "Взорвите колонку teams и запишите данные в таблицу mf.games\n",
    "\n",
    "Поле updated_at должно содержать текущий timestamp\n",
    "\n",
    "Обратите внимание на следующие моменты:\n",
    "+ возникают ли какие-то проблемы из-за параллельной записи разными людьми в одну таблицу?\n",
    "+ создает ли это дубликаты данных?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 5\n",
    "Прочитайте таблицу mf.games с помощью Spark.\n",
    "Используя данные из обеих таблиц, дайте ответ на вопрос:\n",
    "**Какая команда сыграла большего всего домашних игр в самом любимом городе студентов?**\n",
    "\n",
    "+ за какое время время отрабатывает запрос?\n",
    "+ что нужно изменить в схемах данных, чтобы скорость работы запроса выросла?\n",
    "+ скопируйте таблицы (в конце имени новых таблиц поставьте ```_вашу_фамилию```) в таблицы с оптимальной структурой и повторите запрос"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
